{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bản sao của Facial_Expression_DEMO.ipynb","provenance":[{"file_id":"1QnC7lV7oVFk5OZCm75fqbLAfD9qBy9bw","timestamp":1608885904558}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lf4JGQ5oFU7i","executionInfo":{"status":"ok","timestamp":1609037391110,"user_tz":-420,"elapsed":1188,"user":{"displayName":"Dũng Nguyễn Minh","photoUrl":"","userId":"05826558414739051995"}},"outputId":"cc15ef69-c171-421c-e395-5ee86570d867"},"source":["# Mount \"My Drive\" into /content/drive\r\n","from google.colab import drive\r\n","\r\n","google_drive_dir = \"Final_project\"  # @param\r\n","#bml-notebooks/\r\n","drive.mount('/content/drive')\r\n","\r\n","mount_point = \"/content/drive/My Drive/{}\".format(google_drive_dir)\r\n","\r\n","# Change the root directory to your mount_point\r\n","% cd '$mount_point'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/Final_project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Fj9YcAnsT4B_"},"source":["# import dependencies\r\n","from IPython.display import display, Javascript, Image\r\n","from google.colab.output import eval_js\r\n","from base64 import b64decode, b64encode\r\n","from google.colab.patches import cv2_imshow\r\n","import cv2\r\n","import numpy as np\r\n","import PIL\r\n","import io\r\n","import html\r\n","import time\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"09b_0FAnUa9y"},"source":["# function to convert the JavaScript object into an OpenCV image\r\n","def js_to_image(js_reply):\r\n","  \"\"\"\r\n","  Params:\r\n","          js_reply: JavaScript object containing image from webcam\r\n","  Returns:\r\n","          img: OpenCV BGR image\r\n","  \"\"\"\r\n","  # decode base64 image\r\n","  image_bytes = b64decode(js_reply.split(',')[1])\r\n","  # convert bytes to numpy array\r\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\r\n","  # decode numpy array into OpenCV BGR image\r\n","  img = cv2.imdecode(jpg_as_np, flags=1)\r\n","\r\n","  return img\r\n","\r\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\r\n","def bbox_to_bytes(bbox_array):\r\n","  \"\"\"\r\n","  Params:\r\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\r\n","  Returns:\r\n","        bytes: Base64 image byte string\r\n","  \"\"\"\r\n","  # convert array into PIL image\r\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\r\n","  iobuf = io.BytesIO()\r\n","  # format bbox into png for return\r\n","  bbox_PIL.save(iobuf, format='png')\r\n","  # format return string\r\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\r\n","\r\n","  return bbox_bytes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZpA68lTrcvZs"},"source":["# initialize the Haar Cascade face detection model\r\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XwUtEojjnPRb"},"source":["def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","\n","  # get photo data\n","  data = eval_js('takePhoto({})'.format(quality))\n","  # get OpenCV format image\n","  img = js_to_image(data) \n","  # grayscale img\n","  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","  print(gray.shape)\n","  # get face bounding box coordinates using Haar Cascade\n","  faces = face_cascade.detectMultiScale(gray)\n","  # draw face bounding box on image\n","  for (x,y,w,h) in faces:\n","      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n","  # save image\n","  cv2.imwrite(filename, img)\n","\n","  return filename"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghUlAJzKSjFT"},"source":["# JavaScript to properly create our live video stream using our webcam as input\r\n","def video_stream():\r\n","  js = Javascript('''\r\n","    var video;\r\n","    var div = null;\r\n","    var stream;\r\n","    var captureCanvas;\r\n","    var imgElement;\r\n","    var labelElement;\r\n","    \r\n","    var pendingResolve = null;\r\n","    var shutdown = false;\r\n","    \r\n","    function removeDom() {\r\n","       stream.getVideoTracks()[0].stop();\r\n","       video.remove();\r\n","       div.remove();\r\n","       video = null;\r\n","       div = null;\r\n","       stream = null;\r\n","       imgElement = null;\r\n","       captureCanvas = null;\r\n","       labelElement = null;\r\n","    }\r\n","    \r\n","    function onAnimationFrame() {\r\n","      if (!shutdown) {\r\n","        window.requestAnimationFrame(onAnimationFrame);\r\n","      }\r\n","      if (pendingResolve) {\r\n","        var result = \"\";\r\n","        if (!shutdown) {\r\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\r\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\r\n","        }\r\n","        var lp = pendingResolve;\r\n","        pendingResolve = null;\r\n","        lp(result);\r\n","      }\r\n","    }\r\n","    \r\n","    async function createDom() {\r\n","      if (div !== null) {\r\n","        return stream;\r\n","      }\r\n","\r\n","      div = document.createElement('div');\r\n","      div.style.border = '2px solid black';\r\n","      div.style.padding = '3px';\r\n","      div.style.width = '100%';\r\n","      div.style.maxWidth = '600px';\r\n","      document.body.appendChild(div);\r\n","      \r\n","      const modelOut = document.createElement('div');\r\n","      modelOut.innerHTML = \"<span>Status:</span>\";\r\n","      labelElement = document.createElement('span');\r\n","      labelElement.innerText = 'No data';\r\n","      labelElement.style.fontWeight = 'bold';\r\n","      modelOut.appendChild(labelElement);\r\n","      div.appendChild(modelOut);\r\n","           \r\n","      video = document.createElement('video');\r\n","      video.style.display = 'block';\r\n","      video.width = div.clientWidth - 6;\r\n","      video.setAttribute('playsinline', '');\r\n","      video.onclick = () => { shutdown = true; };\r\n","      stream = await navigator.mediaDevices.getUserMedia(\r\n","          {video: { facingMode: \"environment\"}});\r\n","      div.appendChild(video);\r\n","\r\n","      imgElement = document.createElement('img');\r\n","      imgElement.style.position = 'absolute';\r\n","      imgElement.style.zIndex = 1;\r\n","      imgElement.onclick = () => { shutdown = true; };\r\n","      div.appendChild(imgElement);\r\n","      \r\n","      const instruction = document.createElement('div');\r\n","      instruction.innerHTML = \r\n","          '<span style=\"color: red; font-weight: bold;\">' +\r\n","          'Stop this demo</span>';\r\n","      div.appendChild(instruction);\r\n","      instruction.onclick = () => { shutdown = true; };\r\n","      \r\n","      video.srcObject = stream;\r\n","      await video.play();\r\n","\r\n","      captureCanvas = document.createElement('canvas');\r\n","      captureCanvas.width = 640; //video.videoWidth;\r\n","      captureCanvas.height = 480; //video.videoHeight;\r\n","      window.requestAnimationFrame(onAnimationFrame);\r\n","      \r\n","      return stream;\r\n","    }\r\n","    async function stream_frame(label, imgData) {\r\n","      if (shutdown) {\r\n","        removeDom();\r\n","        shutdown = false;\r\n","        return '';\r\n","      }\r\n","\r\n","      var preCreate = Date.now();\r\n","      stream = await createDom();\r\n","      \r\n","      var preShow = Date.now();\r\n","      if (label != \"\") {\r\n","        labelElement.innerHTML = label;\r\n","      }\r\n","            \r\n","      if (imgData != \"\") {\r\n","        var videoRect = video.getClientRects()[0];\r\n","        imgElement.style.top = videoRect.top + \"px\";\r\n","        imgElement.style.left = videoRect.left + \"px\";\r\n","        imgElement.style.width = videoRect.width + \"px\";\r\n","        imgElement.style.height = videoRect.height + \"px\";\r\n","        imgElement.src = imgData;\r\n","      }\r\n","      \r\n","      var preCapture = Date.now();\r\n","      var result = await new Promise(function(resolve, reject) {\r\n","        pendingResolve = resolve;\r\n","      });\r\n","      shutdown = false;\r\n","      \r\n","      return {'create': preShow - preCreate, \r\n","              'show': preCapture - preShow, \r\n","              'capture': Date.now() - preCapture,\r\n","              'img': result};\r\n","    }\r\n","    ''')\r\n","\r\n","  display(js)\r\n","  \r\n","def video_frame(label, bbox):\r\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\r\n","  return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ZDfBU7MTc6D"},"source":["def drawEmotion(image,text,x,y):\r\n","    # font \r\n","    font = cv2.FONT_HERSHEY_SIMPLEX \r\n","    # org \r\n","    org = (x,y)    \r\n","    # fontScale \r\n","    fontScale = 1\r\n","    # Red color in BGR \r\n","    color = (0, 0, 255)  \r\n","    # Line thickness of 2 px \r\n","    thickness = 2\r\n","\r\n","    image = cv2.putText(image, text, org, font, fontScale,  \r\n","                    color, thickness, cv2.LINE_AA, False) \r\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tFOzM06mSmio"},"source":["emotions = {0: 'Angry', 1:'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5: 'Neutral'}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DmAo0b5DZdut"},"source":["from keras import models, Model\r\n","from keras.models import model_from_json\r\n","import numpy as np\r\n","import pickle\r\n","\r\n","def loadModel():\r\n","    json_file = open('keras_model/model.json', 'r')\r\n","    loaded_model_json = json_file.read()\r\n","    json_file.close()\r\n","    loaded_model = model_from_json(loaded_model_json)\r\n","    loaded_model.load_weights(\"keras_model/model.h5\")\r\n","\r\n","    extract = Model(loaded_model.inputs, loaded_model.layers[-3].output) # Dense(128,...)\r\n","    svm = pickle.load(open('saved_model/CNN_svmC1.pkl', 'rb'))\r\n","    return extract,svm,loaded_model\r\n","\r\n","extract,svm, loaded_model= loadModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iF_NfoXtFDMk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAGFfsUFa9B-"},"source":["def recogFaceExpression(face_img,extract,svm,model=None):\r\n","    # load model\r\n","    face_img = cv2.resize(face_img, (48, 48))\r\n","    face_img = np.expand_dims(face_img,axis=[0,-1])\r\n","    face_img = face_img.astype('float32')/255\r\n","    img_feature = extract(face_img)\r\n","    y_pred =  svm.predict(img_feature)[0]\r\n","\r\n","    # y_pred =  np.argmax(model.predict(face_img))\r\n","    return emotions[y_pred]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1nkSnkbkk4cC","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1609037581042,"user_tz":-420,"elapsed":62197,"user":{"displayName":"Dũng Nguyễn Minh","photoUrl":"","userId":"05826558414739051995"}},"outputId":"d20e81e0-46f0-46b6-af0f-62a93f5a1575"},"source":["# start streaming video from webcam\r\n","video_stream()\r\n","# label for video\r\n","label_html = 'Capturing...'\r\n","# initialze bounding box to empty\r\n","bbox = ''\r\n","count = 0 \r\n","while True:\r\n","    js_reply = video_frame(label_html, bbox)\r\n","    if not js_reply:\r\n","        break\r\n","\r\n","    # convert JS response to OpenCV Image\r\n","    img = js_to_image(js_reply[\"img\"])\r\n","\r\n","    # create transparent overlay for bounding box\r\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\r\n","\r\n","    # grayscale image for face detection\r\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\r\n","    # get face region coordinates\r\n","    faces = face_cascade.detectMultiScale(gray)\r\n","\r\n","    # get face bounding box for overlay\r\n","    for (x,y,w,h) in faces:\r\n","      crop_face = gray[y:y+h, x:x+w]\r\n","      crop_face.max()\r\n","      bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\r\n","      bbox_array = drawEmotion(bbox_array,'{}'.format(recogFaceExpression(crop_face,extract,svm,loaded_model)),x,y)\r\n","    \r\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\r\n","    # convert overlay of bbox into bytes\r\n","    bbox_bytes = bbox_to_bytes(bbox_array)\r\n","    # update bbox so next frame gets new overlay\r\n","    bbox = bbox_bytes"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","    \n","    var pendingResolve = null;\n","    var shutdown = false;\n","    \n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","    \n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","    \n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","      \n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","           \n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","      \n","      const instruction = document.createElement('div');\n","      instruction.innerHTML = \n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'Stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","      \n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","      \n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","      \n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","            \n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","      \n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","      \n","      return {'create': preShow - preCreate, \n","              'show': preCapture - preShow, \n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ZI4UBcIvc0Ca"},"source":[""],"execution_count":null,"outputs":[]}]}